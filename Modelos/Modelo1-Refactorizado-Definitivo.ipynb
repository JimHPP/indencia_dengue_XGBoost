{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c846471d",
   "metadata": {},
   "source": [
    "# Selección del set de datos y la elección de las columnas a emplear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b816d25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:17.47963\tvalidation_1-rmse:0.50161\n",
      "[9]\tvalidation_0-rmse:16.89406\tvalidation_1-rmse:0.52350\n",
      "Ji Parana\n",
      "[0]\tvalidation_0-rmse:866.10047\tvalidation_1-rmse:137.69828\n",
      "[489]\tvalidation_0-rmse:214.32166\tvalidation_1-rmse:67.44328\n",
      "Manaus\n",
      "[0]\tvalidation_0-rmse:80.55449\tvalidation_1-rmse:28.09430\n",
      "[125]\tvalidation_0-rmse:53.43115\tvalidation_1-rmse:20.57076\n",
      "Sao Luis\n",
      "[0]\tvalidation_0-rmse:13.20181\tvalidation_1-rmse:4.09171\n",
      "[40]\tvalidation_0-rmse:11.65710\tvalidation_1-rmse:3.69044\n",
      "Parnaiba\n",
      "[0]\tvalidation_0-rmse:29.17675\tvalidation_1-rmse:9.71874\n",
      "[232]\tvalidation_0-rmse:15.44383\tvalidation_1-rmse:4.99339\n",
      "Juazeiro do Norte\n",
      "[0]\tvalidation_0-rmse:7.88908\tvalidation_1-rmse:11.32707\n",
      "[280]\tvalidation_0-rmse:3.91344\tvalidation_1-rmse:9.41442\n",
      "Maranguape\n",
      "[0]\tvalidation_0-rmse:79.79889\tvalidation_1-rmse:4.96854\n",
      "[31]\tvalidation_0-rmse:73.26540\tvalidation_1-rmse:3.41587\n",
      "Sao Vicente\n",
      "[0]\tvalidation_0-rmse:57.45493\tvalidation_1-rmse:0.87898\n",
      "[12]\tvalidation_0-rmse:55.14671\tvalidation_1-rmse:1.18248\n",
      "Sertaozinho\n",
      "[0]\tvalidation_0-rmse:7.43119\tvalidation_1-rmse:0.62929\n",
      "[9]\tvalidation_0-rmse:7.23944\tvalidation_1-rmse:0.65307\n",
      "Santa Cruz do Capibaribe\n",
      "[0]\tvalidation_0-rmse:41.51382\tvalidation_1-rmse:22.62974\n",
      "[224]\tvalidation_0-rmse:20.47554\tvalidation_1-rmse:12.66307\n",
      "Aracaju\n",
      "[0]\tvalidation_0-rmse:9.17205\tvalidation_1-rmse:5.07652\n",
      "[39]\tvalidation_0-rmse:8.18563\tvalidation_1-rmse:4.81861\n",
      "Eunapolis\n",
      "[0]\tvalidation_0-rmse:2862.80467\tvalidation_1-rmse:1731.47220\n",
      "[860]\tvalidation_0-rmse:328.73806\tvalidation_1-rmse:1218.20471\n",
      "Belo Horizonte\n",
      "[0]\tvalidation_0-rmse:32.17626\tvalidation_1-rmse:2.94533\n",
      "[27]\tvalidation_0-rmse:29.63927\tvalidation_1-rmse:2.60581\n",
      "Barra Mansa\n",
      "[0]\tvalidation_0-rmse:2270.13194\tvalidation_1-rmse:476.08193\n",
      "[66]\tvalidation_0-rmse:1847.19902\tvalidation_1-rmse:304.35485\n",
      "Rio de Janeiro\n",
      "[0]\tvalidation_0-rmse:305.52772\tvalidation_1-rmse:58.19431\n",
      "[70]\tvalidation_0-rmse:245.45640\tvalidation_1-rmse:35.68200\n",
      "Sao Goncalo\n",
      "[0]\tvalidation_0-rmse:82.85523\tvalidation_1-rmse:1.20101\n",
      "[14]\tvalidation_0-rmse:79.36359\tvalidation_1-rmse:1.34947\n",
      "Barretos\n",
      "[0]\tvalidation_0-rmse:113.50878\tvalidation_1-rmse:1.44999\n",
      "[10]\tvalidation_0-rmse:111.11337\tvalidation_1-rmse:2.03797\n",
      "Barueri\n",
      "[0]\tvalidation_0-rmse:40.48038\tvalidation_1-rmse:15.56441\n",
      "[105]\tvalidation_0-rmse:30.85448\tvalidation_1-rmse:9.95688\n",
      "Guaruja\n",
      "[0]\tvalidation_0-rmse:66.71974\tvalidation_1-rmse:7.30933\n",
      "[83]\tvalidation_0-rmse:53.10595\tvalidation_1-rmse:5.63666\n",
      "Tres Lagoas\n",
      "[0]\tvalidation_0-rmse:29.62848\tvalidation_1-rmse:0.74651\n",
      "[9]\tvalidation_0-rmse:28.80278\tvalidation_1-rmse:0.93436\n",
      "Rondonopolis\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "paleta_colores = sns.color_palette()\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin'\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "control = 2\n",
    "workbook = load_workbook(filename=r'C:\\Users\\harol\\OneDrive\\Documents\\recoleccion_data.xlsx') \n",
    "sheet = workbook.active\n",
    "def crear_caracteristicas(dataframe):\n",
    "        dataframe[\"week\"] = dataframe.index.isocalendar().week\n",
    "        dataframe[\"week\"] = dataframe[\"week\"].astype(np.int64)\n",
    "        return dataframe\n",
    "ciudad = ['Ji Parana', 'Manaus', 'Sao Luis', 'Parnaiba', 'Juazeiro do Norte', 'Maranguape', 'Sao Vicente', 'Sertaozinho', 'Santa Cruz do Capibaribe', \n",
    "          'Aracaju', 'Eunapolis', 'Belo Horizonte', 'Barra Mansa', 'Rio de Janeiro', 'Sao Goncalo', 'Barretos', 'Barueri', 'Guaruja',\n",
    "         'Tres Lagoas', 'Rondonopolis']\n",
    "for city in ciudad:\n",
    "    for a in range(4):\n",
    "        sheet[f'A{control + a}'] = city\n",
    "        sheet[f'B{control + a}'] = \"XGBoost\"\n",
    "        sheet[f'C{control + a}'] = \"Modelo 1 - AR\"\n",
    "        sheet[f'D{control + a}'] = \"Entrenamiento\"\n",
    "        sheet[f'A{control + a + 4}'] = city\n",
    "        sheet[f'B{control + a + 4}'] = \"XGBoost\"\n",
    "        sheet[f'C{control + a + 4}'] = \"Modelo 1 - AR\"\n",
    "        sheet[f'D{control + a + 4}'] = \"Test\"\n",
    "    dataframe = pd.read_excel(r'C:\\Users\\harol\\Downloads\\dataverse_files\\Dengue_selected_cities.xlsx', sheet_name = city, usecols = [\"date\", \"N_cases\", \"percipitation\", \"humidity\"])\n",
    "    dataframe = dataframe.set_index(\"date\")\n",
    "    dataframe = dataframe.loc[ dataframe.index > \"2011-01-01\"]\n",
    "    \n",
    "    dataframe = crear_caracteristicas(dataframe)\n",
    "    X, y = dataframe[[\"week\", \"percipitation\", \"humidity\"]].values, dataframe['N_cases'].values\n",
    "    df_train, df_test = train_test_split(dataframe, test_size=14, shuffle=False)\n",
    "    X_train, y_train = df_train[[\"week\", \"percipitation\", \"humidity\"]].values, df_train['N_cases'].values.T\n",
    "\n",
    "    X_test, y_test = df_test[[\"week\", \"percipitation\", \"humidity\"]].values, df_test['N_cases'].values.T\n",
    "\n",
    "    model = xgb.XGBRegressor( n_estimators = 10000, \n",
    "                                     max_depth = 7, \n",
    "                                     learning_rate = 0.005,\n",
    "                                    early_stopping_rounds = 10,\n",
    "                                    num_parallel_tree = 4\n",
    "                                   )\n",
    "    model.fit(X_train, y_train,\n",
    "                      eval_set = [ (X_train, y_train),(X_test, y_test) ], \n",
    "                      verbose = 1000)\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions) if r2_score(y_test, predictions) >= 0 else 0.0\n",
    "    sheet[f'E{control + 4}'] = \"RMSE\"\n",
    "    sheet[f'F{control + 4}'] = rmse\n",
    "    sheet[f'E{control + 5}'] = \"R-RMSE\"\n",
    "    sheet[f'F{control + 5}'] = rmse/(np.max(y_test) - np.min(y_test))\n",
    "    sheet[f'E{control + 6}'] = \"R^2\"\n",
    "    sheet[f'F{control + 6}'] = r2\n",
    "    sheet[f'E{control + 7}'] = \"C. Pearson\"\n",
    "    sheet[f'F{control + 7}'] = pearsonr(y_test, predictions)[0]\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_train, predictions) if r2_score(y_train, predictions) >= 0 else 0.0\n",
    "    sheet[f'E{control}'] = \"RMSE\"\n",
    "    sheet[f'F{control}'] = rmse\n",
    "    sheet[f'E{control + 1}'] = \"R-RMSE\"\n",
    "    sheet[f'F{control + 1}'] = rmse/(np.max(y_train) - np.min(y_train))\n",
    "    sheet[f'E{control + 2}'] = \"R^2\"\n",
    "    sheet[f'F{control + 2}'] = r2\n",
    "    sheet[f'E{control + 3}'] = \"C. Pearson\"\n",
    "    sheet[f'F{control + 3}'] = pearsonr(y_train, predictions)[0]\n",
    "    workbook.save(filename=r'C:\\Users\\harol\\OneDrive\\Documents\\recoleccion_data.xlsx')\n",
    "    control += 24\n",
    "    print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b9c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbd1125694492ad93fc406e8f62d212eb010094f580351bea104d541b762e9d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
